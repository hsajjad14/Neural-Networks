{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC321 Tutorial 5: Backpropagation\n",
    "\n",
    "We've seen in lecture that a linear classifier is bound to produce errors if\n",
    "our data is not linearly separable. We can avoid this issue by using a more\n",
    "powerful classifier like a multi-layer perceptron (aka a neural network\n",
    "with fully-connected layers).\n",
    "\n",
    "In this tutorial, we examine a classification problem for which the data\n",
    "is not linearly separable. We will implement a 2-layer neural network and\n",
    "train it using gradient descent, computing gradients using the\n",
    "backpropagation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit as sigmoid\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will generate a toy data set, similar to the one that you saw in \n",
    "http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1df283d3c88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def make_dataset(num_points):\n",
    "    radius = 5\n",
    "    data = []\n",
    "    labels = []\n",
    "    # Generate positive examples (labeled 1).\n",
    "    for i in range(num_points // 2):\n",
    "        r = np.random.uniform(0, radius*0.5)\n",
    "        angle = np.random.uniform(0, 2*math.pi)\n",
    "        x = r * math.sin(angle)\n",
    "        y = r * math.cos(angle)\n",
    "        data.append([x, y])\n",
    "        labels.append(1)\n",
    "        \n",
    "    # Generate negative examples (labeled 0).\n",
    "    for i in range(num_points // 2):\n",
    "        r = np.random.uniform(radius*0.7, radius)\n",
    "        angle = np.random.uniform(0, 2*math.pi)\n",
    "        x = r * math.sin(angle)\n",
    "        y = r * math.cos(angle)\n",
    "        data.append([x, y])\n",
    "        labels.append(0)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    labels = np.asarray(labels)\n",
    "    return data, labels\n",
    "    \n",
    "num_data = 500\n",
    "data, labels = make_dataset(num_data)\n",
    "\n",
    "# Note: red indicates a label of 1, blue indicates a label of 0\n",
    "plt.scatter(data[:num_data//2, 0], data[:num_data//2, 1], color='red') \n",
    "plt.scatter(data[num_data//2:, 0], data[num_data//2:, 1], color='blue')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network definition\n",
    "\n",
    "We will try to classify this data by training a neural network. As a reminder, our goal is to take as input a two dimensional vector $\\mathbf{x} = [x_1, x_2]^T$ and output $\\text{Pr}(t = 1 | \\mathbf{x})$, where $t$ is the label of the datapoint $\\mathbf{x}$. \n",
    "\n",
    "We will use a neural network with one hidden layer which has three hidden units. The equations describing our neural network are below:\n",
    "\n",
    "$$\\mathbf{g} = \\mathbf{U} \\mathbf{x} + \\mathbf{b}$$\n",
    "$$\\mathbf{h} = \\tanh(\\mathbf{g})$$\n",
    "$$z = \\mathbf{W} \\mathbf{h} + c$$\n",
    "$$y = \\sigma(z)$$\n",
    "\n",
    "In the equations above, $\\mathbf{U} = \\begin{pmatrix} u_{11} & u_{12} \\\\ u_{21} & u_{22} \\\\  u_{31} & u_{32} \\end{pmatrix} \\in \\mathbb{R}^{3 \\times 2}, \\mathbf{b} = \\begin{pmatrix} b_1  \\\\ b_2 \\\\ b_3 \\end{pmatrix} \\in \\mathbb{R}^3, \\mathbf{W} = \\begin{pmatrix} w_{1} & w_{2} & w_{3} \\end{pmatrix} \\in \\mathbb{R}^{1 \\times 3}, c \\in \\mathbb{R}$ are the parameters of our neural network which we must learn. Notice we are writing $\\mathbf{W}$ as a matrix with one row.\n",
    "\n",
    "\n",
    "## Vectorizing the neural network\n",
    "\n",
    "We want our neural network to produce predictions for multiple points efficiently. We can do so by vectorizing over training examples. Let  $\\mathbf{X} = \\begin{pmatrix} x_{11} & x_{12} \\\\ \\vdots   & \\vdots  \\\\  x_{N1} & x_{N2}\n",
    "\\end{pmatrix}$ be a matrix containing $N$ datapoints in separate rows. Then we can vectorize by using:\n",
    "\n",
    "$$\\mathbf{G} = \\mathbf{X}\\mathbf{U}^T + \\mathbf{1}\\mathbf{b}^T$$\n",
    "$$\\mathbf{H} = \\tanh(\\mathbf{G})$$\n",
    "$$\\mathbf{z} =  \\mathbf{H}\\mathbf{W}^T + \\mathbf{1}c$$\n",
    "$$\\mathbf{y} = \\sigma(\\mathbf{z})$$\n",
    "\n",
    "$\\mathbf{G}$, for example, will store each of the three hidden unit values for each datapoint in each corresponding row.\n",
    "\n",
    "We can rewrite in scalar form as:\n",
    "$$g_{ij} = u_{j1} x_{i1} + u_{j2} x_{i2} + b_j$$\n",
    "$$h_{ij} = \\tanh(g_{ij})$$\n",
    "$$z_{i} = w_1 h_{i1} + w_2 h_{i2} + w_{3} h_{i3} + c$$\n",
    "$$y_i = \\sigma(z_i)$$\n",
    "Here, $i$ indexes data points and $j$ indexes hidden units, so $i \\in \\{1, \\dots, N\\}$ and $j \\in \\{1, 2, 3\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, initialize our neural network parameters.\n",
    "params = {}\n",
    "params['U'] = np.random.randn(3, 2)\n",
    "params['b'] = np.zeros(3)\n",
    "params['W'] = np.random.randn(3)\n",
    "params['c'] = 0\n",
    "\n",
    "# Notice we make use of numpy's broadcasting when adding the bias b.\n",
    "def forward(X, params):    \n",
    "    G = np.dot(X, params['U'].T)  + params['b']\n",
    "    H = np.tanh(G)\n",
    "    z = np.dot(H, params['W'].T) + params['c']\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network's predictions\n",
    "\n",
    "Let's visualize the predictions of our untrained network. As we can see, the network does not succeed at classifying the points without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 200\n",
    "x1s = np.linspace(-6.0, 6.0, num_points)\n",
    "x2s = np.linspace(-6.0, 6.0, num_points)\n",
    "\n",
    "points = np.transpose([np.tile(x1s, len(x2s)), np.repeat(x2s, len(x1s))])\n",
    "Y = forward(points, params).reshape(num_points, num_points)\n",
    "X1, X2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "plt.pcolormesh(X1, X2, Y, cmap=plt.cm.get_cmap('YlGn'))\n",
    "plt.colorbar()\n",
    "plt.scatter(data[:num_data//2, 0], data[:num_data//2, 1], color='red') \n",
    "plt.scatter(data[num_data//2:, 0], data[num_data//2:, 1], color='blue') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "We will use the same cross entropy loss function as in logistic regression. This loss function is:\n",
    "\n",
    "$$\\mathcal{L}_{CE}(y, t) = -t \\log(y) - (1 - t)\\log(1 - y)$$\n",
    "\n",
    "Here $y = Pr(t = 1|\\mathbf{x})$ and $t$ is the true label.\n",
    "\n",
    "Remember that computing the derivative of this loss function $\\frac{d L}{dy}$ can become numerically unstable. Instead, we combine the logistic function and the cross entropy loss into a single function called logistic cross-entropy:\n",
    "\n",
    "$$\\mathcal{L}_{LCE}(z, t) = t \\log(1 + \\exp(-z)) + (1 -t) \\log(1 + \\exp(z))$$\n",
    "\n",
    "See Lecture 4 Notes for review on this. \n",
    "\n",
    "Our cost function is the sum over multiple examples of the loss function, normalized by the number of examples:\n",
    "\n",
    "$$\\mathcal{E}(\\mathbf{z}, \\mathbf{t}) = \\frac{1}{N} \\left[\\sum_{i=1}^N \\mathcal{L}(z_i, t_i)\\right]$$\n",
    "\n",
    "## Derive backpropagation equations\n",
    "\n",
    "We now derive the backpropagation equations in scalar form and then vectorize on the board.\n",
    "\n",
    "\n",
    "## Implement backpropagation equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X, t, params):\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Perform forwards computation.\n",
    "    G = np.dot(X, params['U'].T)  + params['b']\n",
    "    H = np.tanh(G)\n",
    "    z = np.dot(H, params['W'].T) + params['c']\n",
    "    y = sigmoid(z)\n",
    "    loss = (1./N) * np.sum(-t * np.log(y) - (1 - t) * np.log(1 - y))\n",
    "    \n",
    "    # Perform backwards computation.\n",
    "    E_bar = 1\n",
    "    z_bar = (1./N) * (y - t)\n",
    "    W_bar = np.dot(H.T, z_bar)\n",
    "    c_bar = np.dot(z_bar, np.ones(N))\n",
    "    H_bar = np.outer(z_bar, params['W'].T)\n",
    "    G_bar = H_bar * (1 - np.tanh(G)**2)\n",
    "    U_bar = np.dot(G_bar.T, X)\n",
    "    b_bar = np.dot(G_bar.T, np.ones(N))\n",
    "    \n",
    "    # Wrap our gradients in a dictionary.\n",
    "    grads = {}\n",
    "    grads['U'] = U_bar\n",
    "    grads['b'] = b_bar\n",
    "    grads['W'] = W_bar\n",
    "    grads['c'] = c_bar\n",
    "    \n",
    "    return grads, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "We can train our network parameters using gradient descent once we have computed derivatives using the backpropagation algorithm. Recall that the gradient descent update rule for a given parameter $p$ and a learning rate $\\alpha$ is:\n",
    "\n",
    "$$p \\gets p - \\alpha * \\frac{\\partial \\mathcal{E}}{\\partial p}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "alpha = 1\n",
    "for step in range(num_steps):        \n",
    "    grads, loss = backprop(data, labels, params)\n",
    "    for k in params:\n",
    "        params[k] -= alpha * grads[k]\n",
    "\n",
    "    # Print loss every so often.\n",
    "    if step % 50 == 0:\n",
    "        print(\"Step {:3d} | Loss {:3.2f}\".format(step, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 200\n",
    "x1s = np.linspace(-6.0, 6.0, num_points)\n",
    "x2s = np.linspace(-6.0, 6.0, num_points)\n",
    "\n",
    "points = np.transpose([np.tile(x1s, len(x2s)), np.repeat(x2s, len(x1s))])\n",
    "Y = forward(points, params).reshape(num_points, num_points)\n",
    "X1, X2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "plt.pcolormesh(X1, X2, Y, cmap=plt.cm.get_cmap('YlGn'))\n",
    "plt.colorbar()\n",
    "plt.scatter(data[:num_data//2, 0], data[:num_data//2, 1], color='red') \n",
    "plt.scatter(data[num_data//2:, 0], data[num_data//2:, 1], color='blue') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking forward: Automatic differentiation\n",
    "\n",
    "You probably noticed that manually deriving the backpropagation equations is\n",
    "slow and error prone. It becomes even easier to make an error when implementing\n",
    "in code. Luckily, we almost never have to derive the backwards equations by hand.\n",
    "Instead, we make use of automatic differentation software packaged in libraries\n",
    "such as PyTorch to compute derivatives for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 3)\n",
    "        self.layer2 = nn.Linear(3, 1)\n",
    "    def forward(self, X):\n",
    "        h = torch.tanh(self.layer1(X))\n",
    "        return self.layer2(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.Tensor(data)\n",
    "labels_tensor = torch.Tensor(labels).float()\n",
    "labels_tensor = labels_tensor.reshape([500, 1]) # same shape as `y` below\n",
    "model = PyTorchModel()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "num_steps = 1000\n",
    "for step in range(num_steps):        \n",
    "    y = model(data_tensor) \n",
    "    loss = criterion(y, labels_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Print loss every so often.\n",
    "    if step % 50 == 0:\n",
    "        print(\"Step {:3d} | Loss {:3.2f}\".format(step, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 200\n",
    "x1s = np.linspace(-6.0, 6.0, num_points)\n",
    "x2s = np.linspace(-6.0, 6.0, num_points)\n",
    "\n",
    "points = np.transpose([np.tile(x1s, len(x2s)), np.repeat(x2s, len(x1s))])\n",
    "Y = torch.sigmoid(model(torch.Tensor(points)))\n",
    "Y = Y.detach().numpy() # convert to numpy\n",
    "Y = Y.reshape(num_points, num_points)\n",
    "X1, X2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "plt.pcolormesh(X1, X2, Y, cmap=plt.cm.get_cmap('YlGn'))\n",
    "plt.colorbar()\n",
    "plt.scatter(data[:num_data//2, 0], data[:num_data//2, 1], color='red') \n",
    "plt.scatter(data[num_data//2:, 0], data[num_data//2:, 1], color='blue') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
